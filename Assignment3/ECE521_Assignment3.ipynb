{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('/Users/KP/Desktop/UfT/ECE521_Winter_2018/Assignment 3/Assignment 3/notMNIST.npz') as data :\n",
    "    Data, Target = data [\"images\"], data[\"labels\"]\n",
    "    np.random.seed(521)\n",
    "    randIndx = np.arange(len(Data))\n",
    "    np.random.shuffle(randIndx)\n",
    "    Data = Data[randIndx]/255.\n",
    "    Target = Target[randIndx]\n",
    "    trainData, trainTarget = Data[:15000], Target[:15000]\n",
    "    validData, validTarget = Data[15000:16000], Target[15000:16000]\n",
    "    testData, testTarget = Data[16000:], Target[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainZeros=np.zeros((15000, 10))\n",
    "trainZeros[np.arange(15000),trainTarget]=1\n",
    "trainTarget = trainZeros\n",
    "validZeros=np.zeros((1000, 10))\n",
    "validZeros[np.arange(1000),validTarget]=1\n",
    "validTarget = validZeros\n",
    "testZeros=np.zeros((2724, 10))\n",
    "testZeros[np.arange(2724),testTarget]=1\n",
    "testTarget = testZeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "n_epochs = 20000\n",
    "batch_size = 500\n",
    "n_dim = 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_batches(trainData, trainTarget, batch_size):\n",
    "    batch_indices = np.random.permutation(range(15000)).reshape(-1, batch_size)\n",
    "    X_batches = trainData.reshape(-1, n_dim)[batch_indices]\n",
    "    y_batches = trainTarget[batch_indices]\n",
    "    batches = zip(X_batches, y_batches)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(X, hidden_units):\n",
    "    x_dimension = X.shape[1].value\n",
    "    initializer = tf.contrib.layers.xavier_initializer(uniform=False)\n",
    "    hidden_weights = tf.Variable(initializer([x_dimension, hidden_units]), name='weights')\n",
    "    hidden_biases = tf.Variable(tf.zeros(hidden_units), name='biases')\n",
    "    \n",
    "    return tf.add(tf.matmul(X, hidden_weights), hidden_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = hidden_layer(X,1000)\n",
    "y_ = hidden_layer(tf.nn.relu(y_),10)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=y_))\n",
    "#regularizer = tf.nn.l2_loss(W)\n",
    "#loss = tf.reduce_mean(loss + weight_decay * regularizer)\n",
    "\n",
    "prediction = tf.cast(tf.round(tf.argmax(y_,1)), tf.int8)\n",
    "equality = tf.equal(prediction, tf.cast(tf.argmax(Y,1), tf.int8))\n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "training_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decays = [0.0]\n",
    "valid_accuracies = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for wd in weight_decays:\n",
    "        sess.run(init)\n",
    "        print(\"Weight Decay: {} \\n\".format(wd))\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            batches = grab_batches(trainData, trainTarget, batch_size)\n",
    "            for X_batch, y_batch in batches:\n",
    "                sess.run(training_step, feed_dict={X: X_batch, Y: y_batch})\n",
    "            feed_dict ={X: trainData.reshape(-1,n_dim), Y: trainTarget}\n",
    "            train_loss, train_accuracy = sess.run([loss, accuracy], feed_dict)\n",
    "            print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, train_loss, train_accuracy))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        valid_accuracy = sess.run(accuracy, feed_dict = {X: validData.reshape(-1,n_dim), Y: validTarget})\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        test_accuracy = sess.run(accuracy, feed_dict = {X: testData.reshape(-1,n_dim), Y: testTarget})\n",
    "        test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
